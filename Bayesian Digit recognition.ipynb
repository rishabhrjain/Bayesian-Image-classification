{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GOAL:\n",
    "THe goal of this project is to classify digits by finding statistical features like mean, variance and then using Bayesian posterior probabilities to arrive at a decision. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = scipy.io.loadmat('./data/train_data.mat')\n",
    "test_data = scipy.io.loadmat('./data/test_data.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = train_data['data']\n",
    "train_label = train_data['label'][0]\n",
    "\n",
    "test_images = test_data['data']\n",
    "test_label = test_data['label'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot and image and compare its true label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first image is  3\n"
     ]
    }
   ],
   "source": [
    "print(\"The first image is \", train_label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f0c3da3c88>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1. Data Transformation\n",
    "Each image is a 28X28 matrix containing hand written digits. We have to follow two steps to extract features of an image. \n",
    "\n",
    "Step 1: Feature extraction\n",
    "Each image is stored as a 28x28 array of pixels. For each image i, compute two features: the mean mi and the standard deviation si of the 784 pixels\n",
    "so each image i is now [mi, si] which are two features of the image\n",
    "\n",
    "Step 2: Normalize the features\n",
    "\n",
    "Using training dataset, for every feature calculated in previous step, we find M1, S1 which are mean and standard deviation for first feature. Similarly we calculate M2, S2. \n",
    "\n",
    "For every image i, \n",
    "Yi = [y1i, y2i] = [(mi – M1)/S1, (si – M2)/S2]t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X is  (11548, 2)\n"
     ]
    }
   ],
   "source": [
    "X = np.zeros(shape = (len(images), 2))\n",
    "print(\"train X is \", X.shape)\n",
    "for index, image in enumerate(images):\n",
    "    image_mean = image.mean()\n",
    "    image_std = image.std()\n",
    "    Xi = np.array([image_mean, image_std])\n",
    "    X[index] = Xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_X is  (2886, 2)\n"
     ]
    }
   ],
   "source": [
    "test_X = np.zeros(shape = (len(test_images), 2))\n",
    "print(\"test_X is \", test_X.shape)\n",
    "\n",
    "# take all test images and compress them into their mean and std\n",
    "for index, image in enumerate(test_images):\n",
    "    image_mean = image.mean()\n",
    "    image_std = image.std()\n",
    "    Xi = np.array([image_mean, image_std])\n",
    "    test_X[index] = Xi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Feature normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32.504351071481686, 76.44042397326838)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[M1, M2] = X.mean(axis=0)\n",
    "M1, M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9.349449452973955, 10.509725393032221)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[S1, S2] = X.std(axis = 0)\n",
    "S1, S2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize X which is train features\n",
    "X_normalize = np.zeros(shape = (len(images), 2))\n",
    "\n",
    "for index, Xi in enumerate(X):\n",
    "    x1 = (Xi[0] - M1)/S1\n",
    "    x2 = (Xi[1] - M2)/S2\n",
    "    X_normalize_i = np.array([x1, x2])\n",
    "    X_normalize[index] = X_normalize_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize test images using M1, S1 and M2, S2 calculated using training data\n",
    "\n",
    "X_test_normalize = np.zeros(shape = (len(test_images), 2))\n",
    "\n",
    "for index, Xi in enumerate(test_X):\n",
    "    x1 = (Xi[0] - M1)/S1\n",
    "    x2 = (Xi[1] - M2)/S2\n",
    "    X_test_normalize_i = np.array([x1, x2])\n",
    "    X_test_normalize[index] = X_test_normalize_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2. Density estimation\n",
    "\n",
    "We assume that the 2-d feature space of X_normalize defined above, samples from each class follow a normal distribution. Using the maximum likelihood estimation method, we estimate the parameters for the 2-d normal distribution for each class/digit, using the respective training data for that class/digit.\n",
    "\n",
    "A normal distribution is defined by 2 parameters - mean and variance. We need to calculate co-variance matrix if number of features >=2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_normalize = X_normalize.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_digit3, X_digit7 = [], []\n",
    "\n",
    "for X_i, digit in zip(X_normalize, train_label):\n",
    "    \n",
    "    if(digit == 3):\n",
    "        X_digit3.append(X_i)\n",
    "    else:\n",
    "        X_digit7.append(X_i)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_digit3 = np.array(X_digit3)\n",
    "X_digit7 = np.array(X_digit7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: [0.37687996 0.31851855], Variance: [1.0491056  0.96037982], Co-variance: [[1.04928927 0.98734647]\n",
      " [0.98734647 0.96054796]]\n"
     ]
    }
   ],
   "source": [
    "mean3, var3, cov3 = X_digit3.mean(axis=0), X_digit3.var(axis=0), np.cov(X_digit3[:, 0], X_digit3[:, 1])\n",
    "print(f\"Mean: {mean3}, Variance: {var3}, Co-variance: {cov3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: [-0.36900004 -0.31185886], Variance: [0.67669136 0.842203  ], Co-variance: [[0.67680735 0.74448378]\n",
      " [0.74448378 0.84234736]]\n"
     ]
    }
   ],
   "source": [
    "mean7, var7, cov7 = X_digit7.mean(axis=0), X_digit7.var(axis=0), np.cov(X_digit7[:, 0], X_digit7[:, 1])\n",
    "print(f\"Mean: {mean7}, Variance: {var7}, Co-variance: {cov7}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Bayesian Decision Theory for optimal classification \n",
    "Now we know what are the distributions of features when image is digit 3 and digit 7. For any new image, we can calculate likelihood (using multivariate density equation) using parameters estimated on training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X_normalize)\n",
    "X = X.reshape((-1, 2, 1))\n",
    "\n",
    "test_X = np.array(X_test_normalize)\n",
    "test_X = test_X.reshape((-1, 2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15069489],\n",
       "       [0.12996069]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = X[0]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping matrices and calculating values for the equation of multivariate density\n",
    "mean3 = mean3.reshape((2,1))\n",
    "cov_inverse3 = np.linalg.inv(cov3)\n",
    "determinant3 = np.linalg.det(cov3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean7 = mean7.reshape((2,1))\n",
    "cov_inverse7 = np.linalg.inv(cov7)\n",
    "determinant7 = np.linalg.det(cov7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(x/digit) - based on formula for multivariate normal distribution\n",
    "def likelihood_prob(x, mean, cov_inverse, determinant):\n",
    "    temp = np.matmul(((x - mean).T), cov_inverse)\n",
    "\n",
    "    power = (-1/2) * np.matmul(temp, (x-mean))\n",
    "    power = power[0][0]\n",
    "\n",
    "    exp = np.exp(power)\n",
    "    prob = exp/(2*3.142*np.sqrt(determinant))\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11548, 2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_normalize = np.array(X_normalize)\n",
    "X_normalize.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.  Training and testing error. \n",
    "\n",
    "Let's assume priors of both digits 3 and 7 are equal. \n",
    "since priors of both digits are equal, probability of digit given an image just depends on likelihood (using bayes theorem). \n",
    "\n",
    "We compare the results with the true label and add the probabilty of the incorrect correct class as the error. Its different when compared to accuracy. \n",
    "\n",
    "For example, if the true label is digit 3. Let's say model A predicts P(digit=3/X) = 0.8 and model B predicts P(digit=3/X) = 0.6. Here model B will be penalized more even though we will classify the digit as 3 i.e the model with less confidence will be penalized more. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_error = []\n",
    "p_3, p_7 = 0.5, 0.5\n",
    "\n",
    "# for every image of training data \n",
    "for x, digit in zip(X, train_label):\n",
    "    likelihood_3 = likelihood_prob(x, mean3, cov_inverse3, determinant3 )\n",
    "    likelihood_7 = likelihood_prob(x, mean7, cov_inverse7, determinant7 )\n",
    "    \n",
    "    \n",
    "    if(digit == 3):\n",
    "        train_error.append((likelihood_7 * p_7))\n",
    "    else:\n",
    "        train_error.append((likelihood_3 * p_3))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error prob:  0.21295144830184592\n"
     ]
    }
   ],
   "source": [
    "print(\"training error prob: \", sum(train_error)/len(train_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error on Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Testing error prob:  0.20582431069013368\n"
     ]
    }
   ],
   "source": [
    "test_error = []\n",
    "p_3, p_7 = 0.5, 0.5\n",
    "\n",
    "for x, digit in zip(test_X, test_label):\n",
    "    likelihood_3 = likelihood_prob(x, mean3, cov_inverse3, determinant3 )\n",
    "    likelihood_7 = likelihood_prob(x, mean7, cov_inverse7, determinant7 )\n",
    "    \n",
    "    if(digit == 3):\n",
    "        test_error.append(likelihood_7 * p_7)\n",
    "    else:\n",
    "        test_error.append(likelihood_3 * p_3)\n",
    "        \n",
    "    \n",
    "print(\" Testing error prob: \", sum(test_error)/len(test_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Accuracy\n",
    "The accuracy of model is basically the percentage of digits that the model classified right. In this case since priors of digits 3 and 7 are equal i.e P(digit=3) = P(digit=7). \n",
    "so if likelihood(3) > likelihood(7), we classify as 3 else 7. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.7496536196744025\n"
     ]
    }
   ],
   "source": [
    "# Accuracy on training data\n",
    "correctly_classified = 0\n",
    "p_3, p_7 = 0.5, 0.5\n",
    "\n",
    "# for every image of training data \n",
    "for x, digit in zip(X, train_label):\n",
    "    likelihood_3 = likelihood_prob(x, mean3, cov_inverse3, determinant3 )\n",
    "    likelihood_7 = likelihood_prob(x, mean7, cov_inverse7, determinant7 )\n",
    "    \n",
    "    \n",
    "    if(likelihood_3 > likelihood_7 and digit ==3):\n",
    "        correctly_classified += 1\n",
    "    elif(digit == 7):\n",
    "        correctly_classified += 1   \n",
    "\n",
    "print(\"Training accuracy: \",correctly_classified/len(train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Testing accuracy:  0.762993762993763\n"
     ]
    }
   ],
   "source": [
    "correctly_classified = 0\n",
    "p_3, p_7 = 0.5, 0.5\n",
    "\n",
    "for x, digit in zip(test_X, test_label):\n",
    "    likelihood_3 = likelihood_prob(x, mean3, cov_inverse3, determinant3 )\n",
    "    likelihood_7 = likelihood_prob(x, mean7, cov_inverse7, determinant7 )\n",
    "    \n",
    "    if(likelihood_3 > likelihood_7 and digit == 3):\n",
    "        correctly_classified += 1\n",
    "    elif(digit == 7):\n",
    "        correctly_classified += 1\n",
    "        \n",
    "    \n",
    "print(\" Testing accuracy: \", correctly_classified/len(test_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As wee see, by just extracting two features out of an image, mean and standard deviation, I get a testing accuracy of 76% with almost equally balanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
